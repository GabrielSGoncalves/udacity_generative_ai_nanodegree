{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9380179-fa98-44f0-991f-0fdeb07990ea",
   "metadata": {},
   "source": [
    "# Project 1: Applying Lightweight Fine-Tuning to a Foundation Model <a class=\"jp-toc-ignore\"></a>\n",
    "## Project Introduction <a class=\"jp-toc-ignore\"></a>\n",
    "In this project, you will explore the power of parameter-efficient fine-tuning (PEFT) for adapting large foundation models to your specific needs—without requiring extensive computational resources. Leveraging the Hugging Face peft library, you will implement a workflow that demonstrates how modern generative AI models can be efficiently customized for downstream tasks.\n",
    "\n",
    "The challenge is to bring together all the essential components of a PyTorch + Hugging Face training and inference pipeline. You will load a pre-trained transformer model, perform lightweight fine-tuning using the LoRA (Low-Rank Adaptation) technique, and compare the performance of the original and fine-tuned models on a sequence classification task. This project highlights the practical advantages of PEFT, including reduced training costs and model size, while maintaining strong performance.\n",
    "\n",
    "## Project Structure <a class=\"jp-toc-ignore\"></a>\n",
    "The current project is broken into the following parts:\n",
    "\n",
    "1. **Loading Base Model and Dataset:** Select and load a compatible transformer model and a text classification dataset from Hugging Face. Tokenize and preprocess the data for training and evaluation.\n",
    "2. Baseline Evaluation: Evaluate the pre-trained model’s performance on the selected dataset to establish a reference point.\n",
    "3. PEFT Configuration and Model Conversion: Create a LoRA configuration and convert the base model into a parameter-efficient trainable model.\n",
    "4. Fine-Tuning and Saving: Fine-tune the PEFT model on the dataset, monitor training progress, and save the adapter weights.\n",
    "5. Inference and Comparison: Load the fine-tuned PEFT model, run inference, and compare its performance to the original model to assess the impact of PEFT.\n",
    "6. Results and Insights: Summarize findings, discuss trade-offs, and highlight practical considerations for deploying PEFT in real-world scenarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee9cdb6-8f53-48c8-8a2b-9a7aa3f156e0",
   "metadata": {},
   "source": [
    "# Loading Base Model and Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3693fb0-9a5d-45f0-bb66-0920823ded60",
   "metadata": {},
   "source": [
    "## Base Model\n",
    "As base model we are going to use GPT2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40e24671-e1bd-414d-b8a5-6e668fbe63d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabrielsgoncalves/Documents/Repositories/udacity_generative_ai_nanodegree/project1_fine_tuning_foundational_model/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-21 23:35:39,658] [WARNING] [real_accelerator.py:194:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.\n",
      "[2025-04-21 23:35:39,660] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cpu (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbf3fb89-5288-4b2b-b2cf-b5f745fd883a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt2\"\n",
    "num_labels = 2\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load base model\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    pad_token_id=tokenizer.pad_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bbee36-a7e5-4385-b170-58c2507be76f",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "We are going to use IMDB full dataset with 25.000 samples for each split (train and validate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3cba790-536d-448e-b4fc-de8323b9fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"imdb\", split=['train[:100]', 'test[:100]'])\n",
    "train_dataset, eval_dataset = dataset[0], dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccf75573-c104-4342-9a1a-3ab214ead804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (100, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>text</th><th>label</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;I rented I AM CURIOUS-YELLOW f…</td><td>0</td></tr><tr><td>&quot;&quot;I Am Curious: Yellow&quot; is a ri…</td><td>0</td></tr><tr><td>&quot;If only to avoid making this t…</td><td>0</td></tr><tr><td>&quot;This film was probably inspire…</td><td>0</td></tr><tr><td>&quot;Oh, brother...after hearing ab…</td><td>0</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Sometime in 1998, Saban had ac…</td><td>0</td></tr><tr><td>&quot;This is the biggest insult to …</td><td>0</td></tr><tr><td>&quot;I did not like the idea of the…</td><td>0</td></tr><tr><td>&quot;I cannot stay indifferent to L…</td><td>0</td></tr><tr><td>&quot;This film is terrible. You don…</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (100, 2)\n",
       "┌─────────────────────────────────┬───────┐\n",
       "│ text                            ┆ label │\n",
       "│ ---                             ┆ ---   │\n",
       "│ str                             ┆ i64   │\n",
       "╞═════════════════════════════════╪═══════╡\n",
       "│ I rented I AM CURIOUS-YELLOW f… ┆ 0     │\n",
       "│ \"I Am Curious: Yellow\" is a ri… ┆ 0     │\n",
       "│ If only to avoid making this t… ┆ 0     │\n",
       "│ This film was probably inspire… ┆ 0     │\n",
       "│ Oh, brother...after hearing ab… ┆ 0     │\n",
       "│ …                               ┆ …     │\n",
       "│ Sometime in 1998, Saban had ac… ┆ 0     │\n",
       "│ This is the biggest insult to … ┆ 0     │\n",
       "│ I did not like the idea of the… ┆ 0     │\n",
       "│ I cannot stay indifferent to L… ┆ 0     │\n",
       "│ This film is terrible. You don… ┆ 0     │\n",
       "└─────────────────────────────────┴───────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].to_polars()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af4ddb2-f77b-4bc9-875a-e7d5a5d2ff37",
   "metadata": {},
   "source": [
    "# Tokenizing the text samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "809ec96f-5af0-4755-9785-54ef1dc3c3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████| 25000/25000 [00:03<00:00, 8258.68 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"], \n",
    "        truncation=True, \n",
    "        padding=True, \n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval = eval_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1c86b5-25fb-4ef2-a8ad-21051a61963d",
   "metadata": {},
   "source": [
    "# Defining LoRA Configuration and PEFT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76258dc0-3446-4896-8196-c2849ae8b30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    r=8,  # rank\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"c_proj\", \"c_attn\"],\n",
    "    bias=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b1b59b2-5d4b-477d-8ff3-865d7c47069f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 812,544 || all params: 125,253,888 || trainable%: 0.6487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabrielsgoncalves/Documents/Repositories/udacity_generative_ai_nanodegree/project1_fine_tuning_foundational_model/.venv/lib/python3.12/site-packages/peft/tuners/lora/layer.py:1264: UserWarning:\n",
      "\n",
      "fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create PEFT model\n",
    "peft_model = get_peft_model(base_model, peft_config)\n",
    "peft_model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e080fdb-57b6-4199-982c-2a5a6ed68888",
   "metadata": {},
   "source": [
    "# Training PEFT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b2776a1-2ae2-4853-8216-776ccc05ac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4258f238-f67a-429b-8d99-cb9ec4ace39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"gpt2-imdb-peft\",\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f64c639-47ea-4106-8999-7c8e478e7a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-04 00:24:08,578] [WARNING] [real_accelerator.py:181:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.\n",
      "[2025-03-04 00:24:08,581] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cpu (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f0afc22-2c27-4ef8-ac73-4caa42d10691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9375' max='9375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9375/9375 17:20:16, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.273700</td>\n",
       "      <td>0.220350</td>\n",
       "      <td>0.926600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.278500</td>\n",
       "      <td>0.245032</td>\n",
       "      <td>0.925920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.261500</td>\n",
       "      <td>0.242862</td>\n",
       "      <td>0.933840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9375, training_loss=0.2927575398763021, metrics={'train_runtime': 62423.8985, 'train_samples_per_second': 1.201, 'train_steps_per_second': 0.15, 'total_flos': 1.9784466432e+16, 'train_loss': 0.2927575398763021, 'epoch': 3.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62985199-caf5-4f2d-9e81-258087b5c4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the PEFT model\n",
    "peft_model.save_pretrained(\"gpt2-imdb-peft/best_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efae62b1-39a2-4384-abc4-1eb2ed5bda17",
   "metadata": {},
   "source": [
    "# Comparing the 2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fdbdbbf8-d6ae-4351-a3c8-ff890d91f32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): lora.Linear(\n",
       "            (base_layer): Conv1D(nf=2304, nx=768)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=2304, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (c_proj): lora.Linear(\n",
       "            (base_layer): Conv1D(nf=768, nx=768)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): lora.Linear(\n",
       "            (base_layer): Conv1D(nf=768, nx=3072)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): ModulesToSaveWrapper(\n",
       "    (original_module): Linear(in_features=768, out_features=2, bias=False)\n",
       "    (modules_to_save): ModuleDict(\n",
       "      (default): Linear(in_features=768, out_features=2, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "265bc66c-850a-4a00-b1b6-6cc14e0260aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPT2ForSequenceClassification(\n",
       "      (transformer): GPT2Model(\n",
       "        (wte): Embedding(50257, 768)\n",
       "        (wpe): Embedding(1024, 768)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-11): 12 x GPT2Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPT2Attention(\n",
       "              (c_attn): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=2304, nx=768)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2304, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (c_proj): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=768, nx=768)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): Conv1D(nf=3072, nx=768)\n",
       "              (c_proj): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=768, nx=3072)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=2, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=2, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "199baeb0-19db-42ac-b7da-c684b3fc0895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPT2ForSequenceClassification(\n",
       "      (transformer): GPT2Model(\n",
       "        (wte): Embedding(50257, 768)\n",
       "        (wpe): Embedding(1024, 768)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-11): 12 x GPT2Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPT2Attention(\n",
       "              (c_attn): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=2304, nx=768)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2304, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (c_proj): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=768, nx=768)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): Conv1D(nf=3072, nx=768)\n",
       "              (c_proj): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=768, nx=3072)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=2, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=2, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_peft_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77585487-5d22-4a89-a80d-3e7f9f6965e5",
   "metadata": {},
   "source": [
    "# Inference\n",
    "In this session we are going to define how to perform inferences for both base model, GPT2, and the fine tunned we trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "157aadcb-1940-4992-9a99-dd1332654193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from peft import AutoPeftModelForSequenceClassification\n",
    "\n",
    "# Load the fine-tuned model\n",
    "loaded_peft_model = AutoPeftModelForSequenceClassification.from_pretrained(\n",
    "    \"gpt2-imdb-peft/best_model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0272056-84ed-43e7-bf40-bc5aba105938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference function\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = loaded_peft_model(**inputs)\n",
    "    prediction = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "    return \"Positive\" if prediction[0][1] > prediction[0][0] else \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93f5fe4c-bae9-4d5d-bd6e-a610b7333726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_text = \"This movie was absolutely fantastic! I loved every minute of it.\"\n",
    "print(f\"Sentiment: {predict_sentiment(test_text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7ef916-8ff2-4d0f-92e2-dd3ad38a2bee",
   "metadata": {},
   "source": [
    "# Evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3aa96f2-5652-48ff-80aa-6efa797cf429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset, tokenizer):\n",
    "    # Set up trainer for evaluation only\n",
    "    eval_trainer = Trainer(\n",
    "        model=model,\n",
    "        args=TrainingArguments(\n",
    "            output_dir=\"./eval_output\",\n",
    "            per_device_eval_batch_size=8,\n",
    "            remove_unused_columns=True,\n",
    "        ),\n",
    "        eval_dataset=dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer),\n",
    "    )\n",
    "    \n",
    "    # Run evaluation\n",
    "    eval_results = eval_trainer.evaluate()\n",
    "    return eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50e29d3-bdbb-4197-a0cc-9fcde8dd219a",
   "metadata": {},
   "source": [
    "## Evaluating GPT2 base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f0737e8-f878-4529-bd58-78ee975a6afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating base GPT-2 model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 1:11:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate base model\n",
    "print(\"Evaluating base GPT-2 model...\")\n",
    "base_model_results = evaluate_model(base_model, tokenized_eval, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a947bc0-13b1-4fac-86b7-5badaf53bb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.22035004198551178,\n",
       " 'eval_model_preparation_time': 0.0023,\n",
       " 'eval_accuracy': 0.9266,\n",
       " 'eval_runtime': 4279.2884,\n",
       " 'eval_samples_per_second': 5.842,\n",
       " 'eval_steps_per_second': 0.73}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ab69022-87ac-490f-9888-f66fc7422b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 1:05:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fresh_base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    num_labels=2,\n",
    "    pad_token_id=tokenizer.pad_token_id\n",
    ")\n",
    "base_results = evaluate_model(fresh_base_model, tokenized_eval, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14046177-b31b-4ec0-9cac-698a72dc8c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.8233535885810852,\n",
       " 'eval_model_preparation_time': 0.001,\n",
       " 'eval_accuracy': 0.50304,\n",
       " 'eval_runtime': 3923.0139,\n",
       " 'eval_samples_per_second': 6.373,\n",
       " 'eval_steps_per_second': 0.797}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ff14fff-8830-4109-92f4-8d2343b0a4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset, tokenizer):\n",
    "    # Ensure the model has a padding token set in its config\n",
    "    if hasattr(model, 'config') and model.config.pad_token_id is None:\n",
    "        model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    \n",
    "    # Set up trainer for evaluation only\n",
    "    eval_trainer = Trainer(\n",
    "        model=model,\n",
    "        args=TrainingArguments(\n",
    "            output_dir=\"./eval_output\",\n",
    "            per_device_eval_batch_size=8,\n",
    "            remove_unused_columns=True,\n",
    "        ),\n",
    "        eval_dataset=dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer),\n",
    "    )\n",
    "    \n",
    "    # Run evaluation\n",
    "    eval_results = eval_trainer.evaluate()\n",
    "    return eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a193bd1-4f40-4bd3-953c-2eeac1d0df2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating PEFT fine-tuned model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 1:09:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate PEFT model\n",
    "print(\"Evaluating PEFT fine-tuned model...\")\n",
    "peft_model_results = evaluate_model(peft_model, tokenized_eval, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e7b9696-a6e6-4573-a501-3cb350200047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.22035004198551178,\n",
       " 'eval_model_preparation_time': 0.0024,\n",
       " 'eval_accuracy': 0.9266,\n",
       " 'eval_runtime': 4164.9138,\n",
       " 'eval_samples_per_second': 6.003,\n",
       " 'eval_steps_per_second': 0.75}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "daf40105-56ae-44a8-8838-4d96778d2288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Comparison ===\n",
      "Base GPT-2 Accuracy: 0.5030\n",
      "PEFT Fine-tuned Accuracy: 0.9266\n",
      "Improvement: 42.36%\n"
     ]
    }
   ],
   "source": [
    "# Compare results\n",
    "print(\"\\n=== Model Comparison ===\")\n",
    "print(f\"Base GPT-2 Accuracy: {base_results['eval_accuracy']:.4f}\")\n",
    "print(f\"PEFT Fine-tuned Accuracy: {peft_model_results['eval_accuracy']:.4f}\")\n",
    "print(f\"Improvement: {(peft_model_results['eval_accuracy'] - base_results['eval_accuracy'])*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "570d4fd7-d8aa-4945-9a2b-8af9d13fb39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Comparison ===\n",
      "Base GPT-2 Accuracy: 0.5030\n",
      "PEFT Fine-tuned Accuracy: 0.9266\n",
      "Improvement: 42.36%\n",
      "\n",
      "=== Sample Predictions Comparison ===\n",
      "Example 1:\n",
      "Text: I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-a...\n",
      "True label: Negative\n",
      "Base model prediction: Negative (confidence: 0.88)\n",
      "PEFT model prediction: Negative (confidence: 1.00)\n",
      "--------------------------------------------------\n",
      "Example 2:\n",
      "Text: Worth the entertainment value of a rental, especially if you like action movies. This one features t...\n",
      "True label: Negative\n",
      "Base model prediction: Negative (confidence: 0.78)\n",
      "PEFT model prediction: Negative (confidence: 0.72)\n",
      "--------------------------------------------------\n",
      "Example 3:\n",
      "Text: its a totally average film with a few semi-alright action sequences that make the plot seem a little...\n",
      "True label: Negative\n",
      "Base model prediction: Negative (confidence: 0.70)\n",
      "PEFT model prediction: Negative (confidence: 0.99)\n",
      "--------------------------------------------------\n",
      "Example 4:\n",
      "Text: STAR RATING: ***** Saturday Night **** Friday Night *** Friday Morning ** Sunday Night * Monday Morn...\n",
      "True label: Negative\n",
      "Base model prediction: Negative (confidence: 0.61)\n",
      "PEFT model prediction: Negative (confidence: 1.00)\n",
      "--------------------------------------------------\n",
      "Example 5:\n",
      "Text: First off let me say, If you haven't enjoyed a Van Damme movie since bloodsport, you probably will n...\n",
      "True label: Negative\n",
      "Base model prediction: Negative (confidence: 0.66)\n",
      "PEFT model prediction: Positive (confidence: 1.00)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Compare results\n",
    "print(\"\\n=== Model Comparison ===\")\n",
    "print(f\"Base GPT-2 Accuracy: {base_results['eval_accuracy']:.4f}\")\n",
    "print(f\"PEFT Fine-tuned Accuracy: {peft_model_results['eval_accuracy']:.4f}\")\n",
    "print(f\"Improvement: {(peft_model_results['eval_accuracy'] - base_results['eval_accuracy'])*100:.2f}%\")\n",
    "\n",
    "# Optional: Detailed comparison of specific examples\n",
    "def compare_predictions(model1, model2, examples, tokenizer, num_samples=5):\n",
    "    print(\"\\n=== Sample Predictions Comparison ===\")\n",
    "    for i in range(min(num_samples, len(examples))):\n",
    "        text = examples[i][\"text\"]\n",
    "        true_label = \"Positive\" if examples[i][\"label\"] == 1 else \"Negative\"\n",
    "        \n",
    "        # Get predictions\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Base model prediction\n",
    "            base_outputs = model1(**inputs)\n",
    "            base_pred = torch.nn.functional.softmax(base_outputs.logits, dim=1)\n",
    "            base_sentiment = \"Positive\" if base_pred[0][1] > base_pred[0][0] else \"Negative\"\n",
    "            \n",
    "            # PEFT model prediction\n",
    "            peft_outputs = model2(**inputs)\n",
    "            peft_pred = torch.nn.functional.softmax(peft_outputs.logits, dim=1)\n",
    "            peft_sentiment = \"Positive\" if peft_pred[0][1] > peft_pred[0][0] else \"Negative\"\n",
    "        \n",
    "        print(f\"Example {i+1}:\")\n",
    "        print(f\"Text: {text[:100]}...\")\n",
    "        print(f\"True label: {true_label}\")\n",
    "        print(f\"Base model prediction: {base_sentiment} (confidence: {max(base_pred[0]).item():.2f})\")\n",
    "        print(f\"PEFT model prediction: {peft_sentiment} (confidence: {max(peft_pred[0]).item():.2f})\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Get a few examples from the validation set\n",
    "sample_examples = [eval_dataset[i] for i in range(5)]\n",
    "compare_predictions(fresh_base_model, loaded_peft_model, sample_examples, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
