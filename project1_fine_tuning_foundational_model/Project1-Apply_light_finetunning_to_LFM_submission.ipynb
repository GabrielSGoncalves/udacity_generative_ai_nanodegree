{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9380179-fa98-44f0-991f-0fdeb07990ea",
   "metadata": {},
   "source": [
    "# Project 1: Applying Lightweight Fine-Tuning to a Foundation Model <a class=\"jp-toc-ignore\"></a>\n",
    "## Project Introduction <a class=\"jp-toc-ignore\"></a>\n",
    "In this project, you will explore the power of parameter-efficient fine-tuning (PEFT) for adapting large foundation models to your specific needs—without requiring extensive computational resources. Leveraging the Hugging Face peft library, you will implement a workflow that demonstrates how modern generative AI models can be efficiently customized for downstream tasks.\n",
    "\n",
    "The challenge is to bring together all the essential components of a PyTorch + Hugging Face training and inference pipeline. You will load a pre-trained transformer model, perform lightweight fine-tuning using the LoRA (Low-Rank Adaptation) technique, and compare the performance of the original and fine-tuned models on a sequence classification task. This project highlights the practical advantages of PEFT, including reduced training costs and model size, while maintaining strong performance.\n",
    "\n",
    "## Project Structure <a class=\"jp-toc-ignore\"></a>\n",
    "The current project is broken into the following parts:\n",
    "\n",
    "1. **Loading Base Model and Dataset:** Select and load a compatible transformer model and a text classification dataset from Hugging Face. Tokenize and preprocess the data for training and evaluation.\n",
    "2. **Evaluating Pre Trained Model**: Evaluate the pre-trained model’s performance on the selected dataset to establish a reference point.\n",
    "3. **Defining LoRA Configuration and PEFT model**: Create a LoRA configuration and convert the base model into a parameter-efficient trainable model.\n",
    "4. **Fine-Tuning and Saving:** Fine-tune the PEFT model on the dataset, monitor training progress, and save the adapter weights.\n",
    "5. **Evaluating with PEFT Model:** Load the fine-tuned PEFT model, run inference, and compare its performance to the original model to assess the impact of PEFT.\n",
    "6. **Results and Insights:** Summarize findings, and highlight practical considerations for deploying PEFT in real-world scenarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee9cdb6-8f53-48c8-8a2b-9a7aa3f156e0",
   "metadata": {},
   "source": [
    "# Loading Base Model and Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3693fb0-9a5d-45f0-bb66-0920823ded60",
   "metadata": {},
   "source": [
    "## Base Model\n",
    "As base model we are going to use GPT2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40e24671-e1bd-414d-b8a5-6e668fbe63d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbf3fb89-5288-4b2b-b2cf-b5f745fd883a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt2\"\n",
    "num_labels = 2\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load base model\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    device_map=\"auto\",\n",
    "    pad_token_id=tokenizer.pad_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bbee36-a7e5-4385-b170-58c2507be76f",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "We are going to use IMDB full dataset with 25.000 samples for each split (train and validate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3cba790-536d-448e-b4fc-de8323b9fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"imdb\", split=['train', 'test'])\n",
    "train_dataset, eval_dataset = dataset[0], dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccf75573-c104-4342-9a1a-3ab214ead804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>A hit at the time but now better categorised a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>I love this movie like no other. Another time ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>This film and it's sequel Barry Mckenzie holds...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>'The Adventures Of Barry McKenzie' started lif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>The story centers around Barry McKenzie who mu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
       "1      \"I Am Curious: Yellow\" is a risible and preten...      0\n",
       "2      If only to avoid making this type of film in t...      0\n",
       "3      This film was probably inspired by Godard's Ma...      0\n",
       "4      Oh, brother...after hearing about this ridicul...      0\n",
       "...                                                  ...    ...\n",
       "24995  A hit at the time but now better categorised a...      1\n",
       "24996  I love this movie like no other. Another time ...      1\n",
       "24997  This film and it's sequel Barry Mckenzie holds...      1\n",
       "24998  'The Adventures Of Barry McKenzie' started lif...      1\n",
       "24999  The story centers around Barry McKenzie who mu...      1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af4ddb2-f77b-4bc9-875a-e7d5a5d2ff37",
   "metadata": {},
   "source": [
    "## Tokenizing the text samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "809ec96f-5af0-4755-9785-54ef1dc3c3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9961c45cdd14e9abb61dddfa1661c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b786ef85dc347b69068d934b19530ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"], \n",
    "        truncation=True, \n",
    "        padding=True, \n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval = eval_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7decb0d0-294f-4c30-a260-d977c333d28b",
   "metadata": {},
   "source": [
    "# Evaluating Pre Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c1c3d27-4005-4cc9-9dac-05def134a868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0970a3bd46d84c8d8cd247beb1680d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True).shuffle(seed=666).select(range(5000))\n",
    "tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True).shuffle(seed=666).select(range(250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26b6e6fe-c3ac-4470-94de-0f7d79011752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c288e50-760e-4fca-8c5d-903ec6de2d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewSentiment(Enum):\n",
    "    NEGATIVE = 0\n",
    "    POSITIVE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c2231b5-b376-4548-af4d-6c9dad68fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {v.value: v.name for v in ReviewSentiment}\n",
    "label2id = {v.name: v.value for v in ReviewSentiment}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21fb0db9-395d-48fa-aa32-d13380be9e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(id2label),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1a78acc-8e90-4747-84ea-3cb15cd99237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    # Taken from https://huggingface.co/docs/evaluate/transformers_integrations#trainer\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7ff83ec-6cf5-4049-8da5-3b0f29a70e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d936b7d1ee644bf8ac2c3a6b98af6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric_name = \"accuracy\"\n",
    "metric = evaluate.load(metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf68ba42-8b15-4262-be79-59738a98f0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    evaluate_results_pretrained = Trainer(\n",
    "        model=model,\n",
    "        train_dataset=tokenized_train_dataset,\n",
    "        eval_dataset=tokenized_eval_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer=tokenizer, padding=\"max_length\"),\n",
    "        compute_metrics=compute_metrics\n",
    "    ).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e3044d7-d602-467f-869e-252d15eb3142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.8557566404342651,\n",
       " 'eval_accuracy': 0.428,\n",
       " 'eval_runtime': 22.5326,\n",
       " 'eval_samples_per_second': 11.095,\n",
       " 'eval_steps_per_second': 1.42}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_results_pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1c86b5-25fb-4ef2-a8ad-21051a61963d",
   "metadata": {},
   "source": [
    "# Defining LoRA Configuration and PEFT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76258dc0-3446-4896-8196-c2849ae8b30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    r=8,\n",
    "    inference_mode=True,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    #target_modules=\"all-linear\",\n",
    "    #target_modules=[\"c_proj\", \"c_attn\"],\n",
    "    bias=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b1b59b2-5d4b-477d-8ff3-865d7c47069f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/tuners/lora.py:475: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,072 || all params: 124,737,792 || trainable%: 0.0024627660556954542\n"
     ]
    }
   ],
   "source": [
    "# Create PEFT model\n",
    "peft_model = get_peft_model(base_model, peft_config)\n",
    "peft_model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e080fdb-57b6-4199-982c-2a5a6ed68888",
   "metadata": {},
   "source": [
    "# Fine-Tuning and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b2776a1-2ae2-4853-8216-776ccc05ac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4258f238-f67a-429b-8d99-cb9ec4ace39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"gpt2-imdb-peft\",\n",
    "    learning_rate=1e-3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f64c639-47ea-4106-8999-7c8e478e7a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f0afc22-2c27-4ef8-ac73-4caa42d10691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6250/6250 36:33, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.588800</td>\n",
       "      <td>0.570954</td>\n",
       "      <td>0.844000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.533900</td>\n",
       "      <td>0.495300</td>\n",
       "      <td>0.876000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.423200</td>\n",
       "      <td>0.538966</td>\n",
       "      <td>0.864000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.457200</td>\n",
       "      <td>0.535041</td>\n",
       "      <td>0.872000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.477400</td>\n",
       "      <td>0.476366</td>\n",
       "      <td>0.888000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.447300</td>\n",
       "      <td>0.464938</td>\n",
       "      <td>0.876000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.462300</td>\n",
       "      <td>0.504814</td>\n",
       "      <td>0.864000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.404700</td>\n",
       "      <td>0.444909</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.425300</td>\n",
       "      <td>0.439666</td>\n",
       "      <td>0.884000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.433800</td>\n",
       "      <td>0.436142</td>\n",
       "      <td>0.884000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory gpt2-imdb-peft/checkpoint-625 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory gpt2-imdb-peft/checkpoint-1250 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory gpt2-imdb-peft/checkpoint-1875 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6250, training_loss=0.4646330676269531, metrics={'train_runtime': 2193.7489, 'train_samples_per_second': 22.792, 'train_steps_per_second': 2.849, 'total_flos': 1.31103719424e+16, 'train_loss': 0.4646330676269531, 'epoch': 10.0})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "62985199-caf5-4f2d-9e81-258087b5c4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model.save_pretrained(\"gpt2-imdb-peft/best_model-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ce856f",
   "metadata": {},
   "source": [
    "# Evaluating with PEFT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d82b743f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from peft import AutoPeftModelForSequenceClassification\n",
    "\n",
    "# Load the fine-tuned model\n",
    "loaded_peft_model = AutoPeftModelForSequenceClassification.from_pretrained(\n",
    "    \"gpt2-imdb-peft/best_model-2\",\n",
    "    is_trainable=False, \n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1c7d8e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_peft_model.config.pad_token_id = loaded_peft_model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8bd1b069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_results_peft = Trainer(\n",
    "    model=loaded_peft_model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(\n",
    "        tokenizer=tokenizer, \n",
    "        padding=\"max_length\"),\n",
    "    compute_metrics=compute_metrics\n",
    ").evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f301e6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4361419677734375,\n",
       " 'eval_accuracy': 0.884,\n",
       " 'eval_runtime': 22.2802,\n",
       " 'eval_samples_per_second': 11.221,\n",
       " 'eval_steps_per_second': 1.436}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_results_peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5f1fd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.8557566404342651,\n",
       " 'eval_accuracy': 0.428,\n",
       " 'eval_runtime': 22.5326,\n",
       " 'eval_samples_per_second': 11.095,\n",
       " 'eval_steps_per_second': 1.42}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_results_pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd763b91",
   "metadata": {},
   "source": [
    "# Results and Insights\n",
    "We have demonstrated the potential of using PEFT for fine tuning large language models, without having to retrain it from scratch. The customized PEFT model has double the precision when compared to the original one (88.4% vs 42.8%)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
